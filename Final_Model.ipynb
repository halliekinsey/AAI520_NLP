{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model: Attempt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halladaykinsey/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "from convokit import Corpus, download\n",
    "from transformers import GPT2Tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Local save path for corpus & models\n",
    "save_path = '/Users/halladaykinsey/Desktop/Conversational_Chatbot/conversational_data'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading movie-corpus to /Users/halladaykinsey/.convokit/downloads/movie-corpus\n",
      "Downloading movie-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip (40.9MB)... Done\n",
      "They do not!\n",
      "They do to!\n"
     ]
    }
   ],
   "source": [
    "# Downloading & loading the corpus\n",
    "corpus = Corpus(filename=download(\"movie-corpus\"))\n",
    "\n",
    "# Extracting conversations into a list\n",
    "conversations = list(corpus.iter_conversations())\n",
    "\n",
    "# Saving conversations to a file for later use\n",
    "pd.DataFrame(conversations).to_csv(os.path.join(save_path, 'conversations.csv'), index=False)\n",
    "\n",
    "# Printing a sample conversation for verification\n",
    "for utt_id in conversations[0].get_utterance_ids():\n",
    "    print(corpus.get_utterance(utt_id).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned 0/83097 conversations\n",
      "Cleaned 100/83097 conversations\n",
      "Cleaned 200/83097 conversations\n",
      "Cleaned 300/83097 conversations\n",
      "Cleaned 400/83097 conversations\n",
      "Cleaned 500/83097 conversations\n",
      "Cleaned 600/83097 conversations\n",
      "Cleaned 700/83097 conversations\n",
      "Cleaned 800/83097 conversations\n",
      "Cleaned 900/83097 conversations\n",
      "Cleaned 1000/83097 conversations\n",
      "Cleaned 1100/83097 conversations\n",
      "Cleaned 1200/83097 conversations\n",
      "Cleaned 1300/83097 conversations\n",
      "Cleaned 1400/83097 conversations\n",
      "Cleaned 1500/83097 conversations\n",
      "Cleaned 1600/83097 conversations\n",
      "Cleaned 1700/83097 conversations\n",
      "Cleaned 1800/83097 conversations\n",
      "Cleaned 1900/83097 conversations\n",
      "Cleaned 2000/83097 conversations\n",
      "Cleaned 2100/83097 conversations\n",
      "Cleaned 2200/83097 conversations\n",
      "Cleaned 2300/83097 conversations\n",
      "Cleaned 2400/83097 conversations\n",
      "Cleaned 2500/83097 conversations\n",
      "Cleaned 2600/83097 conversations\n",
      "Cleaned 2700/83097 conversations\n",
      "Cleaned 2800/83097 conversations\n",
      "Cleaned 2900/83097 conversations\n",
      "Cleaned 3000/83097 conversations\n",
      "Cleaned 3100/83097 conversations\n",
      "Cleaned 3200/83097 conversations\n",
      "Cleaned 3300/83097 conversations\n",
      "Cleaned 3400/83097 conversations\n",
      "Cleaned 3500/83097 conversations\n",
      "Cleaned 3600/83097 conversations\n",
      "Cleaned 3700/83097 conversations\n",
      "Cleaned 3800/83097 conversations\n",
      "Cleaned 3900/83097 conversations\n",
      "Cleaned 4000/83097 conversations\n",
      "Cleaned 4100/83097 conversations\n",
      "Cleaned 4200/83097 conversations\n",
      "Cleaned 4300/83097 conversations\n",
      "Cleaned 4400/83097 conversations\n",
      "Cleaned 4500/83097 conversations\n",
      "Cleaned 4600/83097 conversations\n",
      "Cleaned 4700/83097 conversations\n",
      "Cleaned 4800/83097 conversations\n",
      "Cleaned 4900/83097 conversations\n",
      "Cleaned 5000/83097 conversations\n",
      "Cleaned 5100/83097 conversations\n",
      "Cleaned 5200/83097 conversations\n",
      "Cleaned 5300/83097 conversations\n",
      "Cleaned 5400/83097 conversations\n",
      "Cleaned 5500/83097 conversations\n",
      "Cleaned 5600/83097 conversations\n",
      "Cleaned 5700/83097 conversations\n",
      "Cleaned 5800/83097 conversations\n",
      "Cleaned 5900/83097 conversations\n",
      "Cleaned 6000/83097 conversations\n",
      "Cleaned 6100/83097 conversations\n",
      "Cleaned 6200/83097 conversations\n",
      "Cleaned 6300/83097 conversations\n",
      "Cleaned 6400/83097 conversations\n",
      "Cleaned 6500/83097 conversations\n",
      "Cleaned 6600/83097 conversations\n",
      "Cleaned 6700/83097 conversations\n",
      "Cleaned 6800/83097 conversations\n",
      "Cleaned 6900/83097 conversations\n",
      "Cleaned 7000/83097 conversations\n",
      "Cleaned 7100/83097 conversations\n",
      "Cleaned 7200/83097 conversations\n",
      "Cleaned 7300/83097 conversations\n",
      "Cleaned 7400/83097 conversations\n",
      "Cleaned 7500/83097 conversations\n",
      "Cleaned 7600/83097 conversations\n",
      "Cleaned 7700/83097 conversations\n",
      "Cleaned 7800/83097 conversations\n",
      "Cleaned 7900/83097 conversations\n",
      "Cleaned 8000/83097 conversations\n",
      "Cleaned 8100/83097 conversations\n",
      "Cleaned 8200/83097 conversations\n",
      "Cleaned 8300/83097 conversations\n",
      "Cleaned 8400/83097 conversations\n",
      "Cleaned 8500/83097 conversations\n",
      "Cleaned 8600/83097 conversations\n",
      "Cleaned 8700/83097 conversations\n",
      "Cleaned 8800/83097 conversations\n",
      "Cleaned 8900/83097 conversations\n",
      "Cleaned 9000/83097 conversations\n",
      "Cleaned 9100/83097 conversations\n",
      "Cleaned 9200/83097 conversations\n",
      "Cleaned 9300/83097 conversations\n",
      "Cleaned 9400/83097 conversations\n",
      "Cleaned 9500/83097 conversations\n",
      "Cleaned 9600/83097 conversations\n",
      "Cleaned 9700/83097 conversations\n",
      "Cleaned 9800/83097 conversations\n",
      "Cleaned 9900/83097 conversations\n",
      "Cleaned 10000/83097 conversations\n",
      "Cleaned 10100/83097 conversations\n",
      "Cleaned 10200/83097 conversations\n",
      "Cleaned 10300/83097 conversations\n",
      "Cleaned 10400/83097 conversations\n",
      "Cleaned 10500/83097 conversations\n",
      "Cleaned 10600/83097 conversations\n",
      "Cleaned 10700/83097 conversations\n",
      "Cleaned 10800/83097 conversations\n",
      "Cleaned 10900/83097 conversations\n",
      "Cleaned 11000/83097 conversations\n",
      "Cleaned 11100/83097 conversations\n",
      "Cleaned 11200/83097 conversations\n",
      "Cleaned 11300/83097 conversations\n",
      "Cleaned 11400/83097 conversations\n",
      "Cleaned 11500/83097 conversations\n",
      "Cleaned 11600/83097 conversations\n",
      "Cleaned 11700/83097 conversations\n",
      "Cleaned 11800/83097 conversations\n",
      "Cleaned 11900/83097 conversations\n",
      "Cleaned 12000/83097 conversations\n",
      "Cleaned 12100/83097 conversations\n",
      "Cleaned 12200/83097 conversations\n",
      "Cleaned 12300/83097 conversations\n",
      "Cleaned 12400/83097 conversations\n",
      "Cleaned 12500/83097 conversations\n",
      "Cleaned 12600/83097 conversations\n",
      "Cleaned 12700/83097 conversations\n",
      "Cleaned 12800/83097 conversations\n",
      "Cleaned 12900/83097 conversations\n",
      "Cleaned 13000/83097 conversations\n",
      "Cleaned 13100/83097 conversations\n",
      "Cleaned 13200/83097 conversations\n",
      "Cleaned 13300/83097 conversations\n",
      "Cleaned 13400/83097 conversations\n",
      "Cleaned 13500/83097 conversations\n",
      "Cleaned 13600/83097 conversations\n",
      "Cleaned 13700/83097 conversations\n",
      "Cleaned 13800/83097 conversations\n",
      "Cleaned 13900/83097 conversations\n",
      "Cleaned 14000/83097 conversations\n",
      "Cleaned 14100/83097 conversations\n",
      "Cleaned 14200/83097 conversations\n",
      "Cleaned 14300/83097 conversations\n",
      "Cleaned 14400/83097 conversations\n",
      "Cleaned 14500/83097 conversations\n",
      "Cleaned 14600/83097 conversations\n",
      "Cleaned 14700/83097 conversations\n",
      "Cleaned 14800/83097 conversations\n",
      "Cleaned 14900/83097 conversations\n",
      "Cleaned 15000/83097 conversations\n",
      "Cleaned 15100/83097 conversations\n",
      "Cleaned 15200/83097 conversations\n",
      "Cleaned 15300/83097 conversations\n",
      "Cleaned 15400/83097 conversations\n",
      "Cleaned 15500/83097 conversations\n",
      "Cleaned 15600/83097 conversations\n",
      "Cleaned 15700/83097 conversations\n",
      "Cleaned 15800/83097 conversations\n",
      "Cleaned 15900/83097 conversations\n",
      "Cleaned 16000/83097 conversations\n",
      "Cleaned 16100/83097 conversations\n",
      "Cleaned 16200/83097 conversations\n",
      "Cleaned 16300/83097 conversations\n",
      "Cleaned 16400/83097 conversations\n",
      "Cleaned 16500/83097 conversations\n",
      "Cleaned 16600/83097 conversations\n",
      "Cleaned 16700/83097 conversations\n",
      "Cleaned 16800/83097 conversations\n",
      "Cleaned 16900/83097 conversations\n",
      "Cleaned 17000/83097 conversations\n",
      "Cleaned 17100/83097 conversations\n",
      "Cleaned 17200/83097 conversations\n",
      "Cleaned 17300/83097 conversations\n",
      "Cleaned 17400/83097 conversations\n",
      "Cleaned 17500/83097 conversations\n",
      "Cleaned 17600/83097 conversations\n",
      "Cleaned 17700/83097 conversations\n",
      "Cleaned 17800/83097 conversations\n",
      "Cleaned 17900/83097 conversations\n",
      "Cleaned 18000/83097 conversations\n",
      "Cleaned 18100/83097 conversations\n",
      "Cleaned 18200/83097 conversations\n",
      "Cleaned 18300/83097 conversations\n",
      "Cleaned 18400/83097 conversations\n",
      "Cleaned 18500/83097 conversations\n",
      "Cleaned 18600/83097 conversations\n",
      "Cleaned 18700/83097 conversations\n",
      "Cleaned 18800/83097 conversations\n",
      "Cleaned 18900/83097 conversations\n",
      "Cleaned 19000/83097 conversations\n",
      "Cleaned 19100/83097 conversations\n",
      "Cleaned 19200/83097 conversations\n",
      "Cleaned 19300/83097 conversations\n",
      "Cleaned 19400/83097 conversations\n",
      "Cleaned 19500/83097 conversations\n",
      "Cleaned 19600/83097 conversations\n",
      "Cleaned 19700/83097 conversations\n",
      "Cleaned 19800/83097 conversations\n",
      "Cleaned 19900/83097 conversations\n",
      "Cleaned 20000/83097 conversations\n",
      "Cleaned 20100/83097 conversations\n",
      "Cleaned 20200/83097 conversations\n",
      "Cleaned 20300/83097 conversations\n",
      "Cleaned 20400/83097 conversations\n",
      "Cleaned 20500/83097 conversations\n",
      "Cleaned 20600/83097 conversations\n",
      "Cleaned 20700/83097 conversations\n",
      "Cleaned 20800/83097 conversations\n",
      "Cleaned 20900/83097 conversations\n",
      "Cleaned 21000/83097 conversations\n",
      "Cleaned 21100/83097 conversations\n",
      "Cleaned 21200/83097 conversations\n",
      "Cleaned 21300/83097 conversations\n",
      "Cleaned 21400/83097 conversations\n",
      "Cleaned 21500/83097 conversations\n",
      "Cleaned 21600/83097 conversations\n",
      "Cleaned 21700/83097 conversations\n",
      "Cleaned 21800/83097 conversations\n",
      "Cleaned 21900/83097 conversations\n",
      "Cleaned 22000/83097 conversations\n",
      "Cleaned 22100/83097 conversations\n",
      "Cleaned 22200/83097 conversations\n",
      "Cleaned 22300/83097 conversations\n",
      "Cleaned 22400/83097 conversations\n",
      "Cleaned 22500/83097 conversations\n",
      "Cleaned 22600/83097 conversations\n",
      "Cleaned 22700/83097 conversations\n",
      "Cleaned 22800/83097 conversations\n",
      "Cleaned 22900/83097 conversations\n",
      "Cleaned 23000/83097 conversations\n",
      "Cleaned 23100/83097 conversations\n",
      "Cleaned 23200/83097 conversations\n",
      "Cleaned 23300/83097 conversations\n",
      "Cleaned 23400/83097 conversations\n",
      "Cleaned 23500/83097 conversations\n",
      "Cleaned 23600/83097 conversations\n",
      "Cleaned 23700/83097 conversations\n",
      "Cleaned 23800/83097 conversations\n",
      "Cleaned 23900/83097 conversations\n",
      "Cleaned 24000/83097 conversations\n",
      "Cleaned 24100/83097 conversations\n",
      "Cleaned 24200/83097 conversations\n",
      "Cleaned 24300/83097 conversations\n",
      "Cleaned 24400/83097 conversations\n",
      "Cleaned 24500/83097 conversations\n",
      "Cleaned 24600/83097 conversations\n",
      "Cleaned 24700/83097 conversations\n",
      "Cleaned 24800/83097 conversations\n",
      "Cleaned 24900/83097 conversations\n",
      "Cleaned 25000/83097 conversations\n",
      "Cleaned 25100/83097 conversations\n",
      "Cleaned 25200/83097 conversations\n",
      "Cleaned 25300/83097 conversations\n",
      "Cleaned 25400/83097 conversations\n",
      "Cleaned 25500/83097 conversations\n",
      "Cleaned 25600/83097 conversations\n",
      "Cleaned 25700/83097 conversations\n",
      "Cleaned 25800/83097 conversations\n",
      "Cleaned 25900/83097 conversations\n",
      "Cleaned 26000/83097 conversations\n",
      "Cleaned 26100/83097 conversations\n",
      "Cleaned 26200/83097 conversations\n",
      "Cleaned 26300/83097 conversations\n",
      "Cleaned 26400/83097 conversations\n",
      "Cleaned 26500/83097 conversations\n",
      "Cleaned 26600/83097 conversations\n",
      "Cleaned 26700/83097 conversations\n",
      "Cleaned 26800/83097 conversations\n",
      "Cleaned 26900/83097 conversations\n",
      "Cleaned 27000/83097 conversations\n",
      "Cleaned 27100/83097 conversations\n",
      "Cleaned 27200/83097 conversations\n",
      "Cleaned 27300/83097 conversations\n",
      "Cleaned 27400/83097 conversations\n",
      "Cleaned 27500/83097 conversations\n",
      "Cleaned 27600/83097 conversations\n",
      "Cleaned 27700/83097 conversations\n",
      "Cleaned 27800/83097 conversations\n",
      "Cleaned 27900/83097 conversations\n",
      "Cleaned 28000/83097 conversations\n",
      "Cleaned 28100/83097 conversations\n",
      "Cleaned 28200/83097 conversations\n",
      "Cleaned 28300/83097 conversations\n",
      "Cleaned 28400/83097 conversations\n",
      "Cleaned 28500/83097 conversations\n",
      "Cleaned 28600/83097 conversations\n",
      "Cleaned 28700/83097 conversations\n",
      "Cleaned 28800/83097 conversations\n",
      "Cleaned 28900/83097 conversations\n",
      "Cleaned 29000/83097 conversations\n",
      "Cleaned 29100/83097 conversations\n",
      "Cleaned 29200/83097 conversations\n",
      "Cleaned 29300/83097 conversations\n",
      "Cleaned 29400/83097 conversations\n",
      "Cleaned 29500/83097 conversations\n",
      "Cleaned 29600/83097 conversations\n",
      "Cleaned 29700/83097 conversations\n",
      "Cleaned 29800/83097 conversations\n",
      "Cleaned 29900/83097 conversations\n",
      "Cleaned 30000/83097 conversations\n",
      "Cleaned 30100/83097 conversations\n",
      "Cleaned 30200/83097 conversations\n",
      "Cleaned 30300/83097 conversations\n",
      "Cleaned 30400/83097 conversations\n",
      "Cleaned 30500/83097 conversations\n",
      "Cleaned 30600/83097 conversations\n",
      "Cleaned 30700/83097 conversations\n",
      "Cleaned 30800/83097 conversations\n",
      "Cleaned 30900/83097 conversations\n",
      "Cleaned 31000/83097 conversations\n",
      "Cleaned 31100/83097 conversations\n",
      "Cleaned 31200/83097 conversations\n",
      "Cleaned 31300/83097 conversations\n",
      "Cleaned 31400/83097 conversations\n",
      "Cleaned 31500/83097 conversations\n",
      "Cleaned 31600/83097 conversations\n",
      "Cleaned 31700/83097 conversations\n",
      "Cleaned 31800/83097 conversations\n",
      "Cleaned 31900/83097 conversations\n",
      "Cleaned 32000/83097 conversations\n",
      "Cleaned 32100/83097 conversations\n",
      "Cleaned 32200/83097 conversations\n",
      "Cleaned 32300/83097 conversations\n",
      "Cleaned 32400/83097 conversations\n",
      "Cleaned 32500/83097 conversations\n",
      "Cleaned 32600/83097 conversations\n",
      "Cleaned 32700/83097 conversations\n",
      "Cleaned 32800/83097 conversations\n",
      "Cleaned 32900/83097 conversations\n",
      "Cleaned 33000/83097 conversations\n",
      "Cleaned 33100/83097 conversations\n",
      "Cleaned 33200/83097 conversations\n",
      "Cleaned 33300/83097 conversations\n",
      "Cleaned 33400/83097 conversations\n",
      "Cleaned 33500/83097 conversations\n",
      "Cleaned 33600/83097 conversations\n",
      "Cleaned 33700/83097 conversations\n",
      "Cleaned 33800/83097 conversations\n",
      "Cleaned 33900/83097 conversations\n",
      "Cleaned 34000/83097 conversations\n",
      "Cleaned 34100/83097 conversations\n",
      "Cleaned 34200/83097 conversations\n",
      "Cleaned 34300/83097 conversations\n",
      "Cleaned 34400/83097 conversations\n",
      "Cleaned 34500/83097 conversations\n",
      "Cleaned 34600/83097 conversations\n",
      "Cleaned 34700/83097 conversations\n",
      "Cleaned 34800/83097 conversations\n",
      "Cleaned 34900/83097 conversations\n",
      "Cleaned 35000/83097 conversations\n",
      "Cleaned 35100/83097 conversations\n",
      "Cleaned 35200/83097 conversations\n",
      "Cleaned 35300/83097 conversations\n",
      "Cleaned 35400/83097 conversations\n",
      "Cleaned 35500/83097 conversations\n",
      "Cleaned 35600/83097 conversations\n",
      "Cleaned 35700/83097 conversations\n",
      "Cleaned 35800/83097 conversations\n",
      "Cleaned 35900/83097 conversations\n",
      "Cleaned 36000/83097 conversations\n",
      "Cleaned 36100/83097 conversations\n",
      "Cleaned 36200/83097 conversations\n",
      "Cleaned 36300/83097 conversations\n",
      "Cleaned 36400/83097 conversations\n",
      "Cleaned 36500/83097 conversations\n",
      "Cleaned 36600/83097 conversations\n",
      "Cleaned 36700/83097 conversations\n",
      "Cleaned 36800/83097 conversations\n",
      "Cleaned 36900/83097 conversations\n",
      "Cleaned 37000/83097 conversations\n",
      "Cleaned 37100/83097 conversations\n",
      "Cleaned 37200/83097 conversations\n",
      "Cleaned 37300/83097 conversations\n",
      "Cleaned 37400/83097 conversations\n",
      "Cleaned 37500/83097 conversations\n",
      "Cleaned 37600/83097 conversations\n",
      "Cleaned 37700/83097 conversations\n",
      "Cleaned 37800/83097 conversations\n",
      "Cleaned 37900/83097 conversations\n",
      "Cleaned 38000/83097 conversations\n",
      "Cleaned 38100/83097 conversations\n",
      "Cleaned 38200/83097 conversations\n",
      "Cleaned 38300/83097 conversations\n",
      "Cleaned 38400/83097 conversations\n",
      "Cleaned 38500/83097 conversations\n",
      "Cleaned 38600/83097 conversations\n",
      "Cleaned 38700/83097 conversations\n",
      "Cleaned 38800/83097 conversations\n",
      "Cleaned 38900/83097 conversations\n",
      "Cleaned 39000/83097 conversations\n",
      "Cleaned 39100/83097 conversations\n",
      "Cleaned 39200/83097 conversations\n",
      "Cleaned 39300/83097 conversations\n",
      "Cleaned 39400/83097 conversations\n",
      "Cleaned 39500/83097 conversations\n",
      "Cleaned 39600/83097 conversations\n",
      "Cleaned 39700/83097 conversations\n",
      "Cleaned 39800/83097 conversations\n",
      "Cleaned 39900/83097 conversations\n",
      "Cleaned 40000/83097 conversations\n",
      "Cleaned 40100/83097 conversations\n",
      "Cleaned 40200/83097 conversations\n",
      "Cleaned 40300/83097 conversations\n",
      "Cleaned 40400/83097 conversations\n",
      "Cleaned 40500/83097 conversations\n",
      "Cleaned 40600/83097 conversations\n",
      "Cleaned 40700/83097 conversations\n",
      "Cleaned 40800/83097 conversations\n",
      "Cleaned 40900/83097 conversations\n",
      "Cleaned 41000/83097 conversations\n",
      "Cleaned 41100/83097 conversations\n",
      "Cleaned 41200/83097 conversations\n",
      "Cleaned 41300/83097 conversations\n",
      "Cleaned 41400/83097 conversations\n",
      "Cleaned 41500/83097 conversations\n",
      "Cleaned 41600/83097 conversations\n",
      "Cleaned 41700/83097 conversations\n",
      "Cleaned 41800/83097 conversations\n",
      "Cleaned 41900/83097 conversations\n",
      "Cleaned 42000/83097 conversations\n",
      "Cleaned 42100/83097 conversations\n",
      "Cleaned 42200/83097 conversations\n",
      "Cleaned 42300/83097 conversations\n",
      "Cleaned 42400/83097 conversations\n",
      "Cleaned 42500/83097 conversations\n",
      "Cleaned 42600/83097 conversations\n",
      "Cleaned 42700/83097 conversations\n",
      "Cleaned 42800/83097 conversations\n",
      "Cleaned 42900/83097 conversations\n",
      "Cleaned 43000/83097 conversations\n",
      "Cleaned 43100/83097 conversations\n",
      "Cleaned 43200/83097 conversations\n",
      "Cleaned 43300/83097 conversations\n",
      "Cleaned 43400/83097 conversations\n",
      "Cleaned 43500/83097 conversations\n",
      "Cleaned 43600/83097 conversations\n",
      "Cleaned 43700/83097 conversations\n",
      "Cleaned 43800/83097 conversations\n",
      "Cleaned 43900/83097 conversations\n",
      "Cleaned 44000/83097 conversations\n",
      "Cleaned 44100/83097 conversations\n",
      "Cleaned 44200/83097 conversations\n",
      "Cleaned 44300/83097 conversations\n",
      "Cleaned 44400/83097 conversations\n",
      "Cleaned 44500/83097 conversations\n",
      "Cleaned 44600/83097 conversations\n",
      "Cleaned 44700/83097 conversations\n",
      "Cleaned 44800/83097 conversations\n",
      "Cleaned 44900/83097 conversations\n",
      "Cleaned 45000/83097 conversations\n",
      "Cleaned 45100/83097 conversations\n",
      "Cleaned 45200/83097 conversations\n",
      "Cleaned 45300/83097 conversations\n",
      "Cleaned 45400/83097 conversations\n",
      "Cleaned 45500/83097 conversations\n",
      "Cleaned 45600/83097 conversations\n",
      "Cleaned 45700/83097 conversations\n",
      "Cleaned 45800/83097 conversations\n",
      "Cleaned 45900/83097 conversations\n",
      "Cleaned 46000/83097 conversations\n",
      "Cleaned 46100/83097 conversations\n",
      "Cleaned 46200/83097 conversations\n",
      "Cleaned 46300/83097 conversations\n",
      "Cleaned 46400/83097 conversations\n",
      "Cleaned 46500/83097 conversations\n",
      "Cleaned 46600/83097 conversations\n",
      "Cleaned 46700/83097 conversations\n",
      "Cleaned 46800/83097 conversations\n",
      "Cleaned 46900/83097 conversations\n",
      "Cleaned 47000/83097 conversations\n",
      "Cleaned 47100/83097 conversations\n",
      "Cleaned 47200/83097 conversations\n",
      "Cleaned 47300/83097 conversations\n",
      "Cleaned 47400/83097 conversations\n",
      "Cleaned 47500/83097 conversations\n",
      "Cleaned 47600/83097 conversations\n",
      "Cleaned 47700/83097 conversations\n",
      "Cleaned 47800/83097 conversations\n",
      "Cleaned 47900/83097 conversations\n",
      "Cleaned 48000/83097 conversations\n",
      "Cleaned 48100/83097 conversations\n",
      "Cleaned 48200/83097 conversations\n",
      "Cleaned 48300/83097 conversations\n",
      "Cleaned 48400/83097 conversations\n",
      "Cleaned 48500/83097 conversations\n",
      "Cleaned 48600/83097 conversations\n",
      "Cleaned 48700/83097 conversations\n",
      "Cleaned 48800/83097 conversations\n",
      "Cleaned 48900/83097 conversations\n",
      "Cleaned 49000/83097 conversations\n",
      "Cleaned 49100/83097 conversations\n",
      "Cleaned 49200/83097 conversations\n",
      "Cleaned 49300/83097 conversations\n",
      "Cleaned 49400/83097 conversations\n",
      "Cleaned 49500/83097 conversations\n",
      "Cleaned 49600/83097 conversations\n",
      "Cleaned 49700/83097 conversations\n",
      "Cleaned 49800/83097 conversations\n",
      "Cleaned 49900/83097 conversations\n",
      "Cleaned 50000/83097 conversations\n",
      "Cleaned 50100/83097 conversations\n",
      "Cleaned 50200/83097 conversations\n",
      "Cleaned 50300/83097 conversations\n",
      "Cleaned 50400/83097 conversations\n",
      "Cleaned 50500/83097 conversations\n",
      "Cleaned 50600/83097 conversations\n",
      "Cleaned 50700/83097 conversations\n",
      "Cleaned 50800/83097 conversations\n",
      "Cleaned 50900/83097 conversations\n",
      "Cleaned 51000/83097 conversations\n",
      "Cleaned 51100/83097 conversations\n",
      "Cleaned 51200/83097 conversations\n",
      "Cleaned 51300/83097 conversations\n",
      "Cleaned 51400/83097 conversations\n",
      "Cleaned 51500/83097 conversations\n",
      "Cleaned 51600/83097 conversations\n",
      "Cleaned 51700/83097 conversations\n",
      "Cleaned 51800/83097 conversations\n",
      "Cleaned 51900/83097 conversations\n",
      "Cleaned 52000/83097 conversations\n",
      "Cleaned 52100/83097 conversations\n",
      "Cleaned 52200/83097 conversations\n",
      "Cleaned 52300/83097 conversations\n",
      "Cleaned 52400/83097 conversations\n",
      "Cleaned 52500/83097 conversations\n",
      "Cleaned 52600/83097 conversations\n",
      "Cleaned 52700/83097 conversations\n",
      "Cleaned 52800/83097 conversations\n",
      "Cleaned 52900/83097 conversations\n",
      "Cleaned 53000/83097 conversations\n",
      "Cleaned 53100/83097 conversations\n",
      "Cleaned 53200/83097 conversations\n",
      "Cleaned 53300/83097 conversations\n",
      "Cleaned 53400/83097 conversations\n",
      "Cleaned 53500/83097 conversations\n",
      "Cleaned 53600/83097 conversations\n",
      "Cleaned 53700/83097 conversations\n",
      "Cleaned 53800/83097 conversations\n",
      "Cleaned 53900/83097 conversations\n",
      "Cleaned 54000/83097 conversations\n",
      "Cleaned 54100/83097 conversations\n",
      "Cleaned 54200/83097 conversations\n",
      "Cleaned 54300/83097 conversations\n",
      "Cleaned 54400/83097 conversations\n",
      "Cleaned 54500/83097 conversations\n",
      "Cleaned 54600/83097 conversations\n",
      "Cleaned 54700/83097 conversations\n",
      "Cleaned 54800/83097 conversations\n",
      "Cleaned 54900/83097 conversations\n",
      "Cleaned 55000/83097 conversations\n",
      "Cleaned 55100/83097 conversations\n",
      "Cleaned 55200/83097 conversations\n",
      "Cleaned 55300/83097 conversations\n",
      "Cleaned 55400/83097 conversations\n",
      "Cleaned 55500/83097 conversations\n",
      "Cleaned 55600/83097 conversations\n",
      "Cleaned 55700/83097 conversations\n",
      "Cleaned 55800/83097 conversations\n",
      "Cleaned 55900/83097 conversations\n",
      "Cleaned 56000/83097 conversations\n",
      "Cleaned 56100/83097 conversations\n",
      "Cleaned 56200/83097 conversations\n",
      "Cleaned 56300/83097 conversations\n",
      "Cleaned 56400/83097 conversations\n",
      "Cleaned 56500/83097 conversations\n",
      "Cleaned 56600/83097 conversations\n",
      "Cleaned 56700/83097 conversations\n",
      "Cleaned 56800/83097 conversations\n",
      "Cleaned 56900/83097 conversations\n",
      "Cleaned 57000/83097 conversations\n",
      "Cleaned 57100/83097 conversations\n",
      "Cleaned 57200/83097 conversations\n",
      "Cleaned 57300/83097 conversations\n",
      "Cleaned 57400/83097 conversations\n",
      "Cleaned 57500/83097 conversations\n",
      "Cleaned 57600/83097 conversations\n",
      "Cleaned 57700/83097 conversations\n",
      "Cleaned 57800/83097 conversations\n",
      "Cleaned 57900/83097 conversations\n",
      "Cleaned 58000/83097 conversations\n",
      "Cleaned 58100/83097 conversations\n",
      "Cleaned 58200/83097 conversations\n",
      "Cleaned 58300/83097 conversations\n",
      "Cleaned 58400/83097 conversations\n",
      "Cleaned 58500/83097 conversations\n",
      "Cleaned 58600/83097 conversations\n",
      "Cleaned 58700/83097 conversations\n",
      "Cleaned 58800/83097 conversations\n",
      "Cleaned 58900/83097 conversations\n",
      "Cleaned 59000/83097 conversations\n",
      "Cleaned 59100/83097 conversations\n",
      "Cleaned 59200/83097 conversations\n",
      "Cleaned 59300/83097 conversations\n",
      "Cleaned 59400/83097 conversations\n",
      "Cleaned 59500/83097 conversations\n",
      "Cleaned 59600/83097 conversations\n",
      "Cleaned 59700/83097 conversations\n",
      "Cleaned 59800/83097 conversations\n",
      "Cleaned 59900/83097 conversations\n",
      "Cleaned 60000/83097 conversations\n",
      "Cleaned 60100/83097 conversations\n",
      "Cleaned 60200/83097 conversations\n",
      "Cleaned 60300/83097 conversations\n",
      "Cleaned 60400/83097 conversations\n",
      "Cleaned 60500/83097 conversations\n",
      "Cleaned 60600/83097 conversations\n",
      "Cleaned 60700/83097 conversations\n",
      "Cleaned 60800/83097 conversations\n",
      "Cleaned 60900/83097 conversations\n",
      "Cleaned 61000/83097 conversations\n",
      "Cleaned 61100/83097 conversations\n",
      "Cleaned 61200/83097 conversations\n",
      "Cleaned 61300/83097 conversations\n",
      "Cleaned 61400/83097 conversations\n",
      "Cleaned 61500/83097 conversations\n",
      "Cleaned 61600/83097 conversations\n",
      "Cleaned 61700/83097 conversations\n",
      "Cleaned 61800/83097 conversations\n",
      "Cleaned 61900/83097 conversations\n",
      "Cleaned 62000/83097 conversations\n",
      "Cleaned 62100/83097 conversations\n",
      "Cleaned 62200/83097 conversations\n",
      "Cleaned 62300/83097 conversations\n",
      "Cleaned 62400/83097 conversations\n",
      "Cleaned 62500/83097 conversations\n",
      "Cleaned 62600/83097 conversations\n",
      "Cleaned 62700/83097 conversations\n",
      "Cleaned 62800/83097 conversations\n",
      "Cleaned 62900/83097 conversations\n",
      "Cleaned 63000/83097 conversations\n",
      "Cleaned 63100/83097 conversations\n",
      "Cleaned 63200/83097 conversations\n",
      "Cleaned 63300/83097 conversations\n",
      "Cleaned 63400/83097 conversations\n",
      "Cleaned 63500/83097 conversations\n",
      "Cleaned 63600/83097 conversations\n",
      "Cleaned 63700/83097 conversations\n",
      "Cleaned 63800/83097 conversations\n",
      "Cleaned 63900/83097 conversations\n",
      "Cleaned 64000/83097 conversations\n",
      "Cleaned 64100/83097 conversations\n",
      "Cleaned 64200/83097 conversations\n",
      "Cleaned 64300/83097 conversations\n",
      "Cleaned 64400/83097 conversations\n",
      "Cleaned 64500/83097 conversations\n",
      "Cleaned 64600/83097 conversations\n",
      "Cleaned 64700/83097 conversations\n",
      "Cleaned 64800/83097 conversations\n",
      "Cleaned 64900/83097 conversations\n",
      "Cleaned 65000/83097 conversations\n",
      "Cleaned 65100/83097 conversations\n",
      "Cleaned 65200/83097 conversations\n",
      "Cleaned 65300/83097 conversations\n",
      "Cleaned 65400/83097 conversations\n",
      "Cleaned 65500/83097 conversations\n",
      "Cleaned 65600/83097 conversations\n",
      "Cleaned 65700/83097 conversations\n",
      "Cleaned 65800/83097 conversations\n",
      "Cleaned 65900/83097 conversations\n",
      "Cleaned 66000/83097 conversations\n",
      "Cleaned 66100/83097 conversations\n",
      "Cleaned 66200/83097 conversations\n",
      "Cleaned 66300/83097 conversations\n",
      "Cleaned 66400/83097 conversations\n",
      "Cleaned 66500/83097 conversations\n",
      "Cleaned 66600/83097 conversations\n",
      "Cleaned 66700/83097 conversations\n",
      "Cleaned 66800/83097 conversations\n",
      "Cleaned 66900/83097 conversations\n",
      "Cleaned 67000/83097 conversations\n",
      "Cleaned 67100/83097 conversations\n",
      "Cleaned 67200/83097 conversations\n",
      "Cleaned 67300/83097 conversations\n",
      "Cleaned 67400/83097 conversations\n",
      "Cleaned 67500/83097 conversations\n",
      "Cleaned 67600/83097 conversations\n",
      "Cleaned 67700/83097 conversations\n",
      "Cleaned 67800/83097 conversations\n",
      "Cleaned 67900/83097 conversations\n",
      "Cleaned 68000/83097 conversations\n",
      "Cleaned 68100/83097 conversations\n",
      "Cleaned 68200/83097 conversations\n",
      "Cleaned 68300/83097 conversations\n",
      "Cleaned 68400/83097 conversations\n",
      "Cleaned 68500/83097 conversations\n",
      "Cleaned 68600/83097 conversations\n",
      "Cleaned 68700/83097 conversations\n",
      "Cleaned 68800/83097 conversations\n",
      "Cleaned 68900/83097 conversations\n",
      "Cleaned 69000/83097 conversations\n",
      "Cleaned 69100/83097 conversations\n",
      "Cleaned 69200/83097 conversations\n",
      "Cleaned 69300/83097 conversations\n",
      "Cleaned 69400/83097 conversations\n",
      "Cleaned 69500/83097 conversations\n",
      "Cleaned 69600/83097 conversations\n",
      "Cleaned 69700/83097 conversations\n",
      "Cleaned 69800/83097 conversations\n",
      "Cleaned 69900/83097 conversations\n",
      "Cleaned 70000/83097 conversations\n",
      "Cleaned 70100/83097 conversations\n",
      "Cleaned 70200/83097 conversations\n",
      "Cleaned 70300/83097 conversations\n",
      "Cleaned 70400/83097 conversations\n",
      "Cleaned 70500/83097 conversations\n",
      "Cleaned 70600/83097 conversations\n",
      "Cleaned 70700/83097 conversations\n",
      "Cleaned 70800/83097 conversations\n",
      "Cleaned 70900/83097 conversations\n",
      "Cleaned 71000/83097 conversations\n",
      "Cleaned 71100/83097 conversations\n",
      "Cleaned 71200/83097 conversations\n",
      "Cleaned 71300/83097 conversations\n",
      "Cleaned 71400/83097 conversations\n",
      "Cleaned 71500/83097 conversations\n",
      "Cleaned 71600/83097 conversations\n",
      "Cleaned 71700/83097 conversations\n",
      "Cleaned 71800/83097 conversations\n",
      "Cleaned 71900/83097 conversations\n",
      "Cleaned 72000/83097 conversations\n",
      "Cleaned 72100/83097 conversations\n",
      "Cleaned 72200/83097 conversations\n",
      "Cleaned 72300/83097 conversations\n",
      "Cleaned 72400/83097 conversations\n",
      "Cleaned 72500/83097 conversations\n",
      "Cleaned 72600/83097 conversations\n",
      "Cleaned 72700/83097 conversations\n",
      "Cleaned 72800/83097 conversations\n",
      "Cleaned 72900/83097 conversations\n",
      "Cleaned 73000/83097 conversations\n",
      "Cleaned 73100/83097 conversations\n",
      "Cleaned 73200/83097 conversations\n",
      "Cleaned 73300/83097 conversations\n",
      "Cleaned 73400/83097 conversations\n",
      "Cleaned 73500/83097 conversations\n",
      "Cleaned 73600/83097 conversations\n",
      "Cleaned 73700/83097 conversations\n",
      "Cleaned 73800/83097 conversations\n",
      "Cleaned 73900/83097 conversations\n",
      "Cleaned 74000/83097 conversations\n",
      "Cleaned 74100/83097 conversations\n",
      "Cleaned 74200/83097 conversations\n",
      "Cleaned 74300/83097 conversations\n",
      "Cleaned 74400/83097 conversations\n",
      "Cleaned 74500/83097 conversations\n",
      "Cleaned 74600/83097 conversations\n",
      "Cleaned 74700/83097 conversations\n",
      "Cleaned 74800/83097 conversations\n",
      "Cleaned 74900/83097 conversations\n",
      "Cleaned 75000/83097 conversations\n",
      "Cleaned 75100/83097 conversations\n",
      "Cleaned 75200/83097 conversations\n",
      "Cleaned 75300/83097 conversations\n",
      "Cleaned 75400/83097 conversations\n",
      "Cleaned 75500/83097 conversations\n",
      "Cleaned 75600/83097 conversations\n",
      "Cleaned 75700/83097 conversations\n",
      "Cleaned 75800/83097 conversations\n",
      "Cleaned 75900/83097 conversations\n",
      "Cleaned 76000/83097 conversations\n",
      "Cleaned 76100/83097 conversations\n",
      "Cleaned 76200/83097 conversations\n",
      "Cleaned 76300/83097 conversations\n",
      "Cleaned 76400/83097 conversations\n",
      "Cleaned 76500/83097 conversations\n",
      "Cleaned 76600/83097 conversations\n",
      "Cleaned 76700/83097 conversations\n",
      "Cleaned 76800/83097 conversations\n",
      "Cleaned 76900/83097 conversations\n",
      "Cleaned 77000/83097 conversations\n",
      "Cleaned 77100/83097 conversations\n",
      "Cleaned 77200/83097 conversations\n",
      "Cleaned 77300/83097 conversations\n",
      "Cleaned 77400/83097 conversations\n",
      "Cleaned 77500/83097 conversations\n",
      "Cleaned 77600/83097 conversations\n",
      "Cleaned 77700/83097 conversations\n",
      "Cleaned 77800/83097 conversations\n",
      "Cleaned 77900/83097 conversations\n",
      "Cleaned 78000/83097 conversations\n",
      "Cleaned 78100/83097 conversations\n",
      "Cleaned 78200/83097 conversations\n",
      "Cleaned 78300/83097 conversations\n",
      "Cleaned 78400/83097 conversations\n",
      "Cleaned 78500/83097 conversations\n",
      "Cleaned 78600/83097 conversations\n",
      "Cleaned 78700/83097 conversations\n",
      "Cleaned 78800/83097 conversations\n",
      "Cleaned 78900/83097 conversations\n",
      "Cleaned 79000/83097 conversations\n",
      "Cleaned 79100/83097 conversations\n",
      "Cleaned 79200/83097 conversations\n",
      "Cleaned 79300/83097 conversations\n",
      "Cleaned 79400/83097 conversations\n",
      "Cleaned 79500/83097 conversations\n",
      "Cleaned 79600/83097 conversations\n",
      "Cleaned 79700/83097 conversations\n",
      "Cleaned 79800/83097 conversations\n",
      "Cleaned 79900/83097 conversations\n",
      "Cleaned 80000/83097 conversations\n",
      "Cleaned 80100/83097 conversations\n",
      "Cleaned 80200/83097 conversations\n",
      "Cleaned 80300/83097 conversations\n",
      "Cleaned 80400/83097 conversations\n",
      "Cleaned 80500/83097 conversations\n",
      "Cleaned 80600/83097 conversations\n",
      "Cleaned 80700/83097 conversations\n",
      "Cleaned 80800/83097 conversations\n",
      "Cleaned 80900/83097 conversations\n",
      "Cleaned 81000/83097 conversations\n",
      "Cleaned 81100/83097 conversations\n",
      "Cleaned 81200/83097 conversations\n",
      "Cleaned 81300/83097 conversations\n",
      "Cleaned 81400/83097 conversations\n",
      "Cleaned 81500/83097 conversations\n",
      "Cleaned 81600/83097 conversations\n",
      "Cleaned 81700/83097 conversations\n",
      "Cleaned 81800/83097 conversations\n",
      "Cleaned 81900/83097 conversations\n",
      "Cleaned 82000/83097 conversations\n",
      "Cleaned 82100/83097 conversations\n",
      "Cleaned 82200/83097 conversations\n",
      "Cleaned 82300/83097 conversations\n",
      "Cleaned 82400/83097 conversations\n",
      "Cleaned 82500/83097 conversations\n",
      "Cleaned 82600/83097 conversations\n",
      "Cleaned 82700/83097 conversations\n",
      "Cleaned 82800/83097 conversations\n",
      "Cleaned 82900/83097 conversations\n",
      "Cleaned 83000/83097 conversations\n"
     ]
    }
   ],
   "source": [
    "# Function to clean text by removing brackets, punctuation, & spaces\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip() \n",
    "    return text.lower() \n",
    "\n",
    "# Cleaning text for all utterances\n",
    "total_convos = len(conversations)\n",
    "for i, convo in enumerate(conversations):\n",
    "    for utt_id in convo.get_utterance_ids():\n",
    "        utt = corpus.get_utterance(utt_id)\n",
    "        utt.text = clean_text(utt.text)\n",
    "    if i % 100 == 0:  # Printing progress every 100 conversations\n",
    "        print(f\"Cleaned {i}/{total_convos} conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          text\n",
      "0  they do not\n",
      "1   they do to\n",
      "2    i hope so\n",
      "3     she okay\n",
      "4      lets go\n"
     ]
    }
   ],
   "source": [
    "# Creating conversation data\n",
    "conversation_data = []\n",
    "\n",
    "# Looping through processed conversations & collecting text\n",
    "for convo in conversations:\n",
    "    for utt_id in convo.get_utterance_ids():\n",
    "        utt = corpus.get_utterance(utt_id)\n",
    "        processed_text = utt.text\n",
    "        conversation_data.append({'text': processed_text})\n",
    "\n",
    "# Converting conversation data to df\n",
    "df = pd.DataFrame(conversation_data)\n",
    "\n",
    "# Displaying first few rows of df\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n",
      "                                                     text\n",
      "63127                                 my mom wasnt a goat\n",
      "134803  i must protect my interests ms kyle and intere...\n",
      "143713  you said bad things hurt places so maybe good ...\n",
      "216087                             she hates all freshmen\n",
      "165209                              what are you gonna do\n"
     ]
    }
   ],
   "source": [
    "# Creating dictionary to store conversation data\n",
    "conversation_dfs = {}\n",
    "conversation_dfs['all_conversations'] = df\n",
    "\n",
    "# Taking a random sample of 10,000 rows \n",
    "subset_size = 10000 \n",
    "df_subset = df.sample(n=subset_size, random_state=42)\n",
    "\n",
    "print(df_subset.shape)\n",
    "print(df_subset.head())\n",
    "\n",
    "# Splitting the dataset into training and evaluation sets\n",
    "train_df, eval_df = train_test_split(df_subset, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halladaykinsey/myenv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initializing tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define a function to tokenize input and response texts\n",
    "def tokenize_text(text, max_length=128):\n",
    "    return tokenizer.encode(text, truncation=True, padding='max_length', max_length=max_length)\n",
    "\n",
    "# Tokenizing input and response text for training set\n",
    "train_df['input_ids'] = train_df['text'].apply(lambda x: tokenize_text(x))\n",
    "train_df['response_ids'] = train_df['text'].shift(-1).apply(lambda x: tokenize_text(x) if pd.notna(x) else [tokenizer.eos_token_id])\n",
    "\n",
    "# Tokenizing input and response text for evaluation set\n",
    "eval_df['input_ids'] = eval_df['text'].apply(lambda x: tokenize_text(x))\n",
    "eval_df['response_ids'] = eval_df['text'].shift(-1).apply(lambda x: tokenize_text(x) if pd.notna(x) else [tokenizer.eos_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDialoguesDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.input_ids = dataframe['input_ids'].tolist()\n",
    "        self.labels = dataframe['response_ids'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out rows where input_ids or response_ids are not of length 128\n",
    "train_df = train_df[(train_df['input_ids'].apply(len) == 128) & (train_df['response_ids'].apply(len) == 128)]\n",
    "eval_df = eval_df[(eval_df['input_ids'].apply(len) == 128) & (eval_df['response_ids'].apply(len) == 128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 8981\n",
      "Eval dataset size: 995\n"
     ]
    }
   ],
   "source": [
    "# Creating dataset instances\n",
    "train_dataset = MovieDialoguesDataset(train_df)\n",
    "eval_dataset = MovieDialoguesDataset(eval_df)\n",
    "\n",
    "# Checking dataset instances\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Eval dataset size: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs lengths: input_ids\n",
      "128    8981\n",
      "Name: count, dtype: int64\n",
      "Response IDs lengths: response_ids\n",
      "128    8981\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking input & response ID lengths\n",
    "print(\"Input IDs lengths:\", train_df['input_ids'].apply(len).value_counts())\n",
    "print(\"Response IDs lengths:\", train_df['response_ids'].apply(len).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function \n",
    "trainer = None\n",
    "\n",
    "def train_model_for_conversation(dataset):\n",
    "    global trainer\n",
    "\n",
    "    # Loading GPT-2\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    # Defining training arguments for conversation\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(save_path, 'model_results'), \n",
    "        num_train_epochs=2, \n",
    "        per_device_train_batch_size=2,  \n",
    "        per_device_eval_batch_size=2,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=os.path.join(save_path, 'logs'),  \n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",    \n",
    "        load_best_model_at_end=True, \n",
    "    )\n",
    "\n",
    "    # Creating trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "        eval_dataset=eval_dataset  \n",
    "    )\n",
    "\n",
    "    # Training model\n",
    "    trainer.train()\n",
    "\n",
    "    # Saving trained model to local path\n",
    "    model.save_pretrained(os.path.join(save_path, 'trained_conversational_model'))\n",
    "    tokenizer.save_pretrained(os.path.join(save_path, 'trained_conversational_model'))  # Save tokenizer\n",
    "\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halladaykinsey/myenv/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "  0%|          | 10/8982 [00:11<2:26:50,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 12.7561, 'grad_norm': 225.73989868164062, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  0%|          | 10/8982 [01:44<2:26:50,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 13.287164688110352, 'eval_runtime': 93.238, 'eval_samples_per_second': 10.672, 'eval_steps_per_second': 5.341, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/8982 [01:56<5:13:33,  2.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 11.004, 'grad_norm': 226.78887939453125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  0%|          | 20/8982 [03:31<5:13:33,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.524092674255371, 'eval_runtime': 94.7719, 'eval_samples_per_second': 10.499, 'eval_steps_per_second': 5.255, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/8982 [03:41<5:09:46,  2.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.9438, 'grad_norm': 119.64160919189453, 'learning_rate': 3e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  0%|          | 30/8982 [05:16<5:09:46,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.3112101554870605, 'eval_runtime': 95.8652, 'eval_samples_per_second': 10.379, 'eval_steps_per_second': 5.195, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/8982 [05:26<5:07:26,  2.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8138, 'grad_norm': 38.805328369140625, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  0%|          | 40/8982 [06:58<5:07:26,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8046867847442627, 'eval_runtime': 91.9933, 'eval_samples_per_second': 10.816, 'eval_steps_per_second': 5.413, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 50/8982 [07:08<5:03:30,  2.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.598, 'grad_norm': 35.55680847167969, 'learning_rate': 5e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  1%|          | 50/8982 [08:42<5:03:30,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4474492073059082, 'eval_runtime': 93.9426, 'eval_samples_per_second': 10.592, 'eval_steps_per_second': 5.301, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 60/8982 [08:52<5:09:06,  2.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0077, 'grad_norm': 30.959524154663086, 'learning_rate': 6e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  1%|          | 60/8982 [10:28<5:09:06,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2322136163711548, 'eval_runtime': 96.5894, 'eval_samples_per_second': 10.301, 'eval_steps_per_second': 5.156, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 70/8982 [10:40<5:22:13,  2.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5614, 'grad_norm': 13.015396118164062, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  1%|          | 70/8982 [12:13<5:22:13,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.154893398284912, 'eval_runtime': 92.6999, 'eval_samples_per_second': 10.734, 'eval_steps_per_second': 5.372, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 80/8982 [12:23<5:03:45,  2.05s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9707, 'grad_norm': 13.588808059692383, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  1%|          | 80/8982 [13:56<5:03:45,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0686204433441162, 'eval_runtime': 93.1474, 'eval_samples_per_second': 10.682, 'eval_steps_per_second': 5.346, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 90/8982 [14:05<5:01:57,  2.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1687, 'grad_norm': 25.365427017211914, 'learning_rate': 9e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  1%|          | 90/8982 [15:41<5:01:57,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9753501415252686, 'eval_runtime': 95.8951, 'eval_samples_per_second': 10.376, 'eval_steps_per_second': 5.193, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/8982 [15:52<5:36:02,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1953, 'grad_norm': 4.623264312744141, 'learning_rate': 1e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  1%|          | 100/8982 [17:27<5:36:02,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8940721154212952, 'eval_runtime': 94.9598, 'eval_samples_per_second': 10.478, 'eval_steps_per_second': 5.244, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 110/8982 [17:36<5:04:41,  2.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0254, 'grad_norm': 15.71133804321289, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  1%|          | 110/8982 [19:10<5:04:41,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8520007133483887, 'eval_runtime': 93.5919, 'eval_samples_per_second': 10.631, 'eval_steps_per_second': 5.321, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 120/8982 [19:20<5:10:06,  2.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6429, 'grad_norm': 12.167830467224121, 'learning_rate': 1.2e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  1%|▏         | 120/8982 [20:52<5:10:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7836592793464661, 'eval_runtime': 91.9585, 'eval_samples_per_second': 10.82, 'eval_steps_per_second': 5.415, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 130/8982 [21:02<4:57:20,  2.02s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5077, 'grad_norm': 7.217987060546875, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  1%|▏         | 130/8982 [22:39<4:57:20,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.768967866897583, 'eval_runtime': 97.4718, 'eval_samples_per_second': 10.208, 'eval_steps_per_second': 5.109, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 140/8982 [22:49<5:12:21,  2.12s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8115, 'grad_norm': 3.7317817211151123, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  2%|▏         | 140/8982 [24:21<5:12:21,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.765421986579895, 'eval_runtime': 92.1896, 'eval_samples_per_second': 10.793, 'eval_steps_per_second': 5.402, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 150/8982 [24:31<4:58:10,  2.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9785, 'grad_norm': 32.19070816040039, 'learning_rate': 1.5e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  2%|▏         | 150/8982 [26:08<4:58:10,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7573814988136292, 'eval_runtime': 96.8191, 'eval_samples_per_second': 10.277, 'eval_steps_per_second': 5.144, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 160/8982 [26:17<5:07:01,  2.09s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7549, 'grad_norm': 4.792784690856934, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  2%|▏         | 160/8982 [27:49<5:07:01,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7633912563323975, 'eval_runtime': 91.8102, 'eval_samples_per_second': 10.838, 'eval_steps_per_second': 5.424, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 170/8982 [27:59<4:58:11,  2.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6052, 'grad_norm': 11.91805648803711, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  2%|▏         | 170/8982 [29:30<4:58:11,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.782227098941803, 'eval_runtime': 91.7229, 'eval_samples_per_second': 10.848, 'eval_steps_per_second': 5.429, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 180/8982 [29:40<4:58:33,  2.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8482, 'grad_norm': 15.787534713745117, 'learning_rate': 1.8e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  2%|▏         | 180/8982 [31:13<4:58:33,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7484285831451416, 'eval_runtime': 92.8153, 'eval_samples_per_second': 10.72, 'eval_steps_per_second': 5.365, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 190/8982 [31:22<4:57:43,  2.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6797, 'grad_norm': 9.558030128479004, 'learning_rate': 1.9e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  2%|▏         | 190/8982 [32:58<4:57:43,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7376377582550049, 'eval_runtime': 96.0173, 'eval_samples_per_second': 10.363, 'eval_steps_per_second': 5.187, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 200/8982 [33:08<5:02:09,  2.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5914, 'grad_norm': 6.9453301429748535, 'learning_rate': 2e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  2%|▏         | 200/8982 [34:46<5:02:09,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7730563282966614, 'eval_runtime': 97.9523, 'eval_samples_per_second': 10.158, 'eval_steps_per_second': 5.084, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 210/8982 [34:55<5:04:02,  2.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7969, 'grad_norm': 16.71982192993164, 'learning_rate': 2.1e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  2%|▏         | 210/8982 [36:30<5:04:02,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7590102553367615, 'eval_runtime': 95.2236, 'eval_samples_per_second': 10.449, 'eval_steps_per_second': 5.23, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 220/8982 [36:40<4:58:05,  2.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6488, 'grad_norm': 20.064926147460938, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  2%|▏         | 220/8982 [38:10<4:58:05,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7452864646911621, 'eval_runtime': 90.3078, 'eval_samples_per_second': 11.018, 'eval_steps_per_second': 5.514, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 230/8982 [38:20<4:51:14,  2.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3537, 'grad_norm': 10.655451774597168, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  3%|▎         | 230/8982 [39:57<4:51:14,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7939386963844299, 'eval_runtime': 97.8464, 'eval_samples_per_second': 10.169, 'eval_steps_per_second': 5.09, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 240/8982 [40:07<5:01:12,  2.07s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6137, 'grad_norm': 3.812127113342285, 'learning_rate': 2.4e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  3%|▎         | 240/8982 [41:43<5:01:12,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7432315349578857, 'eval_runtime': 96.5353, 'eval_samples_per_second': 10.307, 'eval_steps_per_second': 5.159, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 250/8982 [41:53<5:07:08,  2.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7728, 'grad_norm': 10.535128593444824, 'learning_rate': 2.5e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  3%|▎         | 250/8982 [43:29<5:07:08,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7861974835395813, 'eval_runtime': 96.1392, 'eval_samples_per_second': 10.35, 'eval_steps_per_second': 5.18, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 260/8982 [43:39<5:06:26,  2.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8077, 'grad_norm': 9.04298210144043, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  3%|▎         | 260/8982 [49:20<5:06:26,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7289537191390991, 'eval_runtime': 340.9982, 'eval_samples_per_second': 2.918, 'eval_steps_per_second': 1.46, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 270/8982 [49:31<12:23:07,  5.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7384, 'grad_norm': 10.024827003479004, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  3%|▎         | 270/8982 [51:03<12:23:07,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7296831607818604, 'eval_runtime': 91.9316, 'eval_samples_per_second': 10.823, 'eval_steps_per_second': 5.417, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 280/8982 [51:13<5:03:33,  2.09s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6311, 'grad_norm': 43.645442962646484, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  3%|▎         | 280/8982 [52:48<5:03:33,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7777179479598999, 'eval_runtime': 94.9007, 'eval_samples_per_second': 10.485, 'eval_steps_per_second': 5.248, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 290/8982 [52:57<5:01:47,  2.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4039, 'grad_norm': 5.0722784996032715, 'learning_rate': 2.9e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  3%|▎         | 290/8982 [54:36<5:01:47,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7596169114112854, 'eval_runtime': 99.1318, 'eval_samples_per_second': 10.037, 'eval_steps_per_second': 5.024, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 300/8982 [54:46<5:07:17,  2.12s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1128, 'grad_norm': 11.951732635498047, 'learning_rate': 3e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  3%|▎         | 300/8982 [56:18<5:07:17,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7700353860855103, 'eval_runtime': 92.1221, 'eval_samples_per_second': 10.801, 'eval_steps_per_second': 5.406, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 310/8982 [56:28<4:53:29,  2.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4994, 'grad_norm': 31.20751190185547, 'learning_rate': 3.1e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  3%|▎         | 310/8982 [58:00<4:53:29,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.76714026927948, 'eval_runtime': 91.7883, 'eval_samples_per_second': 10.84, 'eval_steps_per_second': 5.426, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 320/8982 [58:09<4:52:05,  2.02s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.79, 'grad_norm': 3.9634838104248047, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  4%|▎         | 320/8982 [1:01:48<4:52:05,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7585521936416626, 'eval_runtime': 218.4296, 'eval_samples_per_second': 4.555, 'eval_steps_per_second': 2.28, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 330/8982 [1:01:58<8:30:22,  3.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6143, 'grad_norm': 5.89286994934082, 'learning_rate': 3.3e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  4%|▎         | 330/8982 [1:03:26<8:30:22,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7334747910499573, 'eval_runtime': 88.5268, 'eval_samples_per_second': 11.24, 'eval_steps_per_second': 5.625, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 340/8982 [1:03:36<4:51:10,  2.02s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8197, 'grad_norm': 4.248692989349365, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  4%|▍         | 340/8982 [1:05:02<4:51:10,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7188882231712341, 'eval_runtime': 86.3882, 'eval_samples_per_second': 11.518, 'eval_steps_per_second': 5.765, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 350/8982 [1:05:12<4:41:24,  1.96s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7969, 'grad_norm': 10.747626304626465, 'learning_rate': 3.5e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  4%|▍         | 350/8982 [1:06:44<4:41:24,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7218369841575623, 'eval_runtime': 91.5087, 'eval_samples_per_second': 10.873, 'eval_steps_per_second': 5.442, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 360/8982 [1:06:53<4:50:51,  2.02s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7067, 'grad_norm': 13.693099021911621, 'learning_rate': 3.6e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  4%|▍         | 360/8982 [1:08:25<4:50:51,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.715442419052124, 'eval_runtime': 91.5553, 'eval_samples_per_second': 10.868, 'eval_steps_per_second': 5.439, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 370/8982 [1:08:34<4:46:52,  2.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4952, 'grad_norm': 4.46554708480835, 'learning_rate': 3.7e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  4%|▍         | 370/8982 [1:10:04<4:46:52,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8134557008743286, 'eval_runtime': 89.3011, 'eval_samples_per_second': 11.142, 'eval_steps_per_second': 5.577, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 380/8982 [1:10:13<4:41:26,  1.96s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.824, 'grad_norm': 12.475844383239746, 'learning_rate': 3.8e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  4%|▍         | 380/8982 [1:11:43<4:41:26,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7219618558883667, 'eval_runtime': 89.7109, 'eval_samples_per_second': 11.091, 'eval_steps_per_second': 5.551, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 390/8982 [1:11:52<4:50:53,  2.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0781, 'grad_norm': 19.894636154174805, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  4%|▍         | 390/8982 [1:13:20<4:50:53,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.741669774055481, 'eval_runtime': 87.8866, 'eval_samples_per_second': 11.321, 'eval_steps_per_second': 5.666, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 400/8982 [1:13:30<4:44:17,  1.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6871, 'grad_norm': 7.530923843383789, 'learning_rate': 4e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  4%|▍         | 400/8982 [1:14:58<4:44:17,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7725932598114014, 'eval_runtime': 88.5067, 'eval_samples_per_second': 11.242, 'eval_steps_per_second': 5.627, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 410/8982 [1:15:08<4:41:19,  1.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6749, 'grad_norm': 12.001233100891113, 'learning_rate': 4.1e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  5%|▍         | 410/8982 [1:16:39<4:41:19,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7639809250831604, 'eval_runtime': 90.4922, 'eval_samples_per_second': 10.995, 'eval_steps_per_second': 5.503, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 420/8982 [1:16:48<4:51:54,  2.05s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5663, 'grad_norm': 19.694570541381836, 'learning_rate': 4.2e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  5%|▍         | 420/8982 [1:18:18<4:51:54,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7200566530227661, 'eval_runtime': 90.2528, 'eval_samples_per_second': 11.025, 'eval_steps_per_second': 5.518, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 430/8982 [1:18:28<4:44:03,  1.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.718, 'grad_norm': 7.53505802154541, 'learning_rate': 4.3e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  5%|▍         | 430/8982 [1:19:58<4:44:03,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7132872343063354, 'eval_runtime': 90.2092, 'eval_samples_per_second': 11.03, 'eval_steps_per_second': 5.52, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 440/8982 [1:20:08<4:49:54,  2.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0859, 'grad_norm': 3.3442037105560303, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  5%|▍         | 440/8982 [1:21:40<4:49:54,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7192938327789307, 'eval_runtime': 91.5253, 'eval_samples_per_second': 10.871, 'eval_steps_per_second': 5.441, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 450/8982 [1:21:51<5:13:50,  2.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6907, 'grad_norm': 4.642205715179443, 'learning_rate': 4.5e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  5%|▌         | 450/8982 [1:26:51<5:13:50,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7263298630714417, 'eval_runtime': 300.5338, 'eval_samples_per_second': 3.311, 'eval_steps_per_second': 1.657, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 460/8982 [1:27:02<11:37:36,  4.91s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6052, 'grad_norm': 7.136635780334473, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  5%|▌         | 460/8982 [1:28:27<11:37:36,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8042763471603394, 'eval_runtime': 84.8913, 'eval_samples_per_second': 11.721, 'eval_steps_per_second': 5.866, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 470/8982 [1:28:36<4:32:45,  1.92s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9245, 'grad_norm': 3.0325064659118652, 'learning_rate': 4.7e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  5%|▌         | 470/8982 [1:30:01<4:32:45,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7295767664909363, 'eval_runtime': 84.6808, 'eval_samples_per_second': 11.75, 'eval_steps_per_second': 5.881, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 480/8982 [1:30:09<4:23:17,  1.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5705, 'grad_norm': 6.795499324798584, 'learning_rate': 4.8e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  5%|▌         | 480/8982 [1:31:36<4:23:17,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7218373417854309, 'eval_runtime': 86.0463, 'eval_samples_per_second': 11.564, 'eval_steps_per_second': 5.788, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 490/8982 [1:31:44<4:23:55,  1.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8097, 'grad_norm': 7.625492095947266, 'learning_rate': 4.9e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  5%|▌         | 490/8982 [1:33:12<4:23:55,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7263543605804443, 'eval_runtime': 87.4239, 'eval_samples_per_second': 11.381, 'eval_steps_per_second': 5.696, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 500/8982 [1:33:21<4:25:37,  1.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6295, 'grad_norm': 7.837323188781738, 'learning_rate': 5e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  6%|▌         | 500/8982 [1:34:53<4:25:37,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7308434247970581, 'eval_runtime': 92.1516, 'eval_samples_per_second': 10.797, 'eval_steps_per_second': 5.404, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 510/8982 [1:35:04<4:41:02,  1.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.882, 'grad_norm': 2.5392556190490723, 'learning_rate': 4.994105163876445e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  6%|▌         | 510/8982 [1:36:34<4:41:02,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7174102067947388, 'eval_runtime': 90.5318, 'eval_samples_per_second': 10.991, 'eval_steps_per_second': 5.501, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 520/8982 [1:36:43<4:34:26,  1.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6176, 'grad_norm': 2.4369993209838867, 'learning_rate': 4.9882103277528884e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  6%|▌         | 520/8982 [1:38:14<4:34:26,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7373520731925964, 'eval_runtime': 90.9649, 'eval_samples_per_second': 10.938, 'eval_steps_per_second': 5.475, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 530/8982 [1:38:23<4:33:03,  1.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4594, 'grad_norm': 2.190375328063965, 'learning_rate': 4.982315491629333e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  6%|▌         | 530/8982 [1:39:56<4:33:03,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7759990096092224, 'eval_runtime': 93.7189, 'eval_samples_per_second': 10.617, 'eval_steps_per_second': 5.314, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 540/8982 [1:40:05<4:36:39,  1.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5292, 'grad_norm': 4.201676845550537, 'learning_rate': 4.976420655505777e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  6%|▌         | 540/8982 [1:43:14<4:36:39,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7408835291862488, 'eval_runtime': 188.8116, 'eval_samples_per_second': 5.27, 'eval_steps_per_second': 2.638, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 550/8982 [1:43:23<7:22:29,  3.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.597, 'grad_norm': 3.916090488433838, 'learning_rate': 4.970525819382221e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  6%|▌         | 550/8982 [1:44:52<7:22:29,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7820221781730652, 'eval_runtime': 88.8805, 'eval_samples_per_second': 11.195, 'eval_steps_per_second': 5.603, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 560/8982 [1:45:02<4:35:55,  1.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3935, 'grad_norm': 2.952568769454956, 'learning_rate': 4.9646309832586655e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  6%|▌         | 560/8982 [1:46:32<4:35:55,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7576313614845276, 'eval_runtime': 90.1143, 'eval_samples_per_second': 11.042, 'eval_steps_per_second': 5.526, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 570/8982 [1:46:41<4:31:12,  1.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6958, 'grad_norm': 9.688631057739258, 'learning_rate': 4.95873614713511e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  6%|▋         | 570/8982 [1:48:12<4:31:12,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7609564065933228, 'eval_runtime': 91.5174, 'eval_samples_per_second': 10.872, 'eval_steps_per_second': 5.442, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 580/8982 [1:48:21<4:36:28,  1.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8719, 'grad_norm': 6.546107769012451, 'learning_rate': 4.952841311011554e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  6%|▋         | 580/8982 [1:49:48<4:36:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7293756604194641, 'eval_runtime': 86.9699, 'eval_samples_per_second': 11.441, 'eval_steps_per_second': 5.726, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 590/8982 [1:49:57<4:23:48,  1.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.86, 'grad_norm': 23.958505630493164, 'learning_rate': 4.946946474887998e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  7%|▋         | 590/8982 [1:51:28<4:23:48,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7581551671028137, 'eval_runtime': 90.7497, 'eval_samples_per_second': 10.964, 'eval_steps_per_second': 5.488, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 600/8982 [1:51:37<4:31:45,  1.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0699, 'grad_norm': 7.325691223144531, 'learning_rate': 4.9410516387644426e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  7%|▋         | 600/8982 [2:02:32<4:31:45,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7260693907737732, 'eval_runtime': 655.8013, 'eval_samples_per_second': 1.517, 'eval_steps_per_second': 0.759, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 610/8982 [2:02:42<20:29:36,  8.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.639, 'grad_norm': 1.2969063520431519, 'learning_rate': 4.935156802640887e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  7%|▋         | 610/8982 [2:04:09<20:29:36,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7679963111877441, 'eval_runtime': 87.1415, 'eval_samples_per_second': 11.418, 'eval_steps_per_second': 5.715, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 620/8982 [2:04:18<4:50:58,  2.09s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0717, 'grad_norm': 2.810419797897339, 'learning_rate': 4.9292619665173315e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  7%|▋         | 620/8982 [2:05:49<4:50:58,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7204889059066772, 'eval_runtime': 91.1097, 'eval_samples_per_second': 10.921, 'eval_steps_per_second': 5.466, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 630/8982 [2:05:58<4:33:08,  1.96s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7598, 'grad_norm': 10.782885551452637, 'learning_rate': 4.923367130393775e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  7%|▋         | 630/8982 [2:07:29<4:33:08,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7082875370979309, 'eval_runtime': 90.5231, 'eval_samples_per_second': 10.992, 'eval_steps_per_second': 5.501, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 640/8982 [2:07:39<5:08:12,  2.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.807, 'grad_norm': 4.408230304718018, 'learning_rate': 4.91747229427022e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  7%|▋         | 640/8982 [2:09:06<5:08:12,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7118021845817566, 'eval_runtime': 86.0712, 'eval_samples_per_second': 11.56, 'eval_steps_per_second': 5.786, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 650/8982 [2:09:15<4:26:04,  1.92s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0928, 'grad_norm': 3.7372682094573975, 'learning_rate': 4.911577458146664e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  7%|▋         | 650/8982 [2:10:44<4:26:04,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7119852304458618, 'eval_runtime': 89.0386, 'eval_samples_per_second': 11.175, 'eval_steps_per_second': 5.593, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 660/8982 [2:10:53<4:25:36,  1.92s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6392, 'grad_norm': 5.44580078125, 'learning_rate': 4.905682622023108e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  7%|▋         | 660/8982 [2:12:20<4:25:36,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7180932760238647, 'eval_runtime': 87.4665, 'eval_samples_per_second': 11.376, 'eval_steps_per_second': 5.694, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 670/8982 [2:12:29<4:24:30,  1.91s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8921, 'grad_norm': 3.24893856048584, 'learning_rate': 4.8997877858995523e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  7%|▋         | 670/8982 [3:12:20<4:24:30,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7249559164047241, 'eval_runtime': 3591.0549, 'eval_samples_per_second': 0.277, 'eval_steps_per_second': 0.139, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 680/8982 [3:59:19<516:02:30, 223.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.026, 'grad_norm': 4.157061576843262, 'learning_rate': 4.893892949775997e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      "  8%|▊         | 680/8982 [10:50:54<516:02:30, 223.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7660076022148132, 'eval_runtime': 24694.5579, 'eval_samples_per_second': 0.04, 'eval_steps_per_second': 0.02, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 690/8982 [10:51:07<705:53:20, 306.46s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5782, 'grad_norm': 2.7078917026519775, 'learning_rate': 4.8879981136524405e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      "  8%|▊         | 690/8982 [10:52:56<705:53:20, 306.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7605716586112976, 'eval_runtime': 108.9711, 'eval_samples_per_second': 9.131, 'eval_steps_per_second': 4.57, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 700/8982 [10:53:08<25:19:10, 11.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4542, 'grad_norm': 4.265566825866699, 'learning_rate': 4.882103277528885e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "  8%|▊         | 700/8982 [10:54:59<25:19:10, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7116566896438599, 'eval_runtime': 111.3937, 'eval_samples_per_second': 8.932, 'eval_steps_per_second': 4.471, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 710/8982 [10:55:11<6:13:01,  2.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6493, 'grad_norm': 1.2409753799438477, 'learning_rate': 4.8762084414053294e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  8%|▊         | 710/8982 [10:57:04<6:13:01,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7099127173423767, 'eval_runtime': 112.8346, 'eval_samples_per_second': 8.818, 'eval_steps_per_second': 4.414, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 719/8982 [10:57:14<7:03:32,  3.08s/it] "
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "train_model_for_conversation(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498/498 [01:34<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "=====================\n",
      "eval_loss: 0.7101\n",
      "eval_runtime: 95.4551\n",
      "eval_samples_per_second: 10.4240\n",
      "eval_steps_per_second: 5.2170\n",
      "epoch: 3.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "if trainer is not None:  \n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Printing metrics \n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(\"=====================\")\n",
    "    for key, value in eval_results.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "else:\n",
    "    print(\"Trainer is not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model from saved path\n",
    "model_path = '/Users/halladaykinsey/Desktop/Conversational_Chatbot/trained_conversational_model'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def generate_response(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    attention_mask = (input_ids != tokenizer.pad_token_id).long()  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, \n",
    "                                attention_mask=attention_mask, \n",
    "                                max_length=150, \n",
    "                                num_return_sequences=1,\n",
    "                                temperature=0.9,  \n",
    "                                top_k=50,        \n",
    "                                top_p=0.95)\n",
    "\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "conversation_history = \"\"\n",
    "\n",
    "def chat():\n",
    "    global conversation_history\n",
    "    print(\"Welcome to the chatbot! Type 'exit' to end the conversation.\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        \n",
    "        # Appending user input to conversation history\n",
    "        conversation_history += f\"You: {user_input}\\n\"\n",
    "        \n",
    "        # Generating response based on the updated conversation history\n",
    "        response = generate_response(conversation_history)\n",
    "        \n",
    "        print(f\"Bot: {response}\")\n",
    "        \n",
    "        # Appending bot's response to conversation history\n",
    "        conversation_history += f\"Bot: {response}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the chatbot! Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: You: Hello\n",
      "Bot: You: Hello\n",
      "\n",
      "You: How are you?\n",
      "Bot: You: Hello\n",
      "Bot: You: Hello\n",
      "\n",
      "You: How are you?\n",
      "\n",
      "You: If I lived in Los Angeles, what movie would you recommend watching on a cold and stormy Saturday night?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input length of input_ids is 157, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mUntitled-5.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m \u001b[39m# Start chatting\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m chat()\n",
      "\u001b[1;32mUntitled-5.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=35'>36</a>\u001b[0m conversation_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou: \u001b[39m\u001b[39m{\u001b[39;00muser_input\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=37'>38</a>\u001b[0m \u001b[39m# Generate response based on the updated conversation history\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=38'>39</a>\u001b[0m response \u001b[39m=\u001b[39m generate_response(conversation_history)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBot: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=42'>43</a>\u001b[0m \u001b[39m# Append the bot's response to the conversation history\u001b[39;00m\n",
      "\u001b[1;32mUntitled-5.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=9'>10</a>\u001b[0m attention_mask \u001b[39m=\u001b[39m (input_ids \u001b[39m!=\u001b[39m tokenizer\u001b[39m.\u001b[39mpad_token_id)\u001b[39m.\u001b[39mlong()  \u001b[39m# Adjust this line to create attention mask\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=11'>12</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=12'>13</a>\u001b[0m     output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(input_ids, \n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=13'>14</a>\u001b[0m                             attention_mask\u001b[39m=\u001b[39;49mattention_mask, \n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=14'>15</a>\u001b[0m                             max_length\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=15'>16</a>\u001b[0m                             num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=16'>17</a>\u001b[0m                             temperature\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,   \u001b[39m# Adjust temperature\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=17'>18</a>\u001b[0m                             top_k\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,          \u001b[39m# Adjust top-k\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=18'>19</a>\u001b[0m                             top_p\u001b[39m=\u001b[39;49m\u001b[39m0.95\u001b[39;49m)        \u001b[39m# Adjust top-p\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=20'>21</a>\u001b[0m response \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(output[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-5.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=21'>22</a>\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/transformers/generation/utils.py:1906\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_supports_num_logits_to_keep() \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnum_logits_to_keep\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1904\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_logits_to_keep\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1906\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_generated_length(generation_config, input_ids_length, has_default_max_length)\n\u001b[1;32m   1908\u001b[0m \u001b[39m# 7. Prepare the cache.\u001b[39;00m\n\u001b[1;32m   1909\u001b[0m \u001b[39m# - `model_kwargs` may be updated in place with a cache as defined by the parameters in `generation_config`.\u001b[39;00m\n\u001b[1;32m   1910\u001b[0m \u001b[39m# - different models have a different cache name expected by the model (default = \"past_key_values\")\u001b[39;00m\n\u001b[1;32m   1911\u001b[0m \u001b[39m# - `max_length`, prepared above, is used to determine the maximum cache length\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[39m# TODO (joao): remove `user_defined_cache` after v4.47 (remove default conversion to legacy format)\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m cache_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpast_key_values\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmamba\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m.\u001b[39mlower() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcache_params\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/transformers/generation/utils.py:1228\u001b[0m, in \u001b[0;36mGenerationMixin._validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[39mif\u001b[39;00m input_ids_length \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m generation_config\u001b[39m.\u001b[39mmax_length:\n\u001b[1;32m   1227\u001b[0m     input_ids_string \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdecoder_input_ids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1228\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1229\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput length of \u001b[39m\u001b[39m{\u001b[39;00minput_ids_string\u001b[39m}\u001b[39;00m\u001b[39m is \u001b[39m\u001b[39m{\u001b[39;00minput_ids_length\u001b[39m}\u001b[39;00m\u001b[39m, but `max_length` is set to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1230\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mgeneration_config\u001b[39m.\u001b[39mmax_length\u001b[39m}\u001b[39;00m\u001b[39m. This can lead to unexpected behavior. You should consider\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1231\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m increasing `max_length` or, better yet, setting `max_new_tokens`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1232\u001b[0m     )\n\u001b[1;32m   1234\u001b[0m \u001b[39m# 2. Min length warnings due to unfeasible parameter combinations\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m min_length_error_suffix \u001b[39m=\u001b[39m (\n\u001b[1;32m   1236\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m Generation will stop at the defined maximum length. You should decrease the minimum length and/or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1237\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mincrease the maximum length.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1238\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 157, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
     ]
    }
   ],
   "source": [
    "# Starting chat\n",
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
